{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_DATA_PATH = 'medquad.csv'\n",
    "MODEL_SAVE_PATH = 'healthcare_bot_model.pkl'\n",
    "SAMPLE_SIZE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "def log(message):\n",
    "    \"\"\"Simple logging function that includes timestamps\"\"\"\n",
    "    print(f\"[{time.strftime('%H:%M:%S')}] {message}\")\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and normalize text\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "        \n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Convert to lowercase for consistency\n",
    "    text = text.lower()\n",
    "    # Remove punctuation that might interfere with matching\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def truncate_text(text, max_length=1000):\n",
    "    \"\"\"Truncate very long answers to a reasonable length\"\"\"\n",
    "    if len(text) <= max_length:\n",
    "        return text\n",
    "    \n",
    "    # Try to find a period to break at\n",
    "    cutoff = text[:max_length].rfind('.')\n",
    "    if cutoff > max_length // 2:\n",
    "        return text[:cutoff+1]\n",
    "    \n",
    "    return text[:max_length] + \"...\"\n",
    "\n",
    "def validate_csv_file(filepath):\n",
    "    \"\"\"Check if the file exists and is readable\"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        log(f\"Error: File {filepath} does not exist\")\n",
    "        return False\n",
    "    \n",
    "    if not os.path.isfile(filepath):\n",
    "        log(f\"Error: {filepath} is not a file\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            sample = f.read(1024)\n",
    "            if not sample:\n",
    "                log(f\"Error: File {filepath} is empty\")\n",
    "                return False\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        log(f\"Error validating file: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_medquad_data(filepath, max_samples=None):\n",
    "    \"\"\"Load QA pairs from medquad.csv using pandas\"\"\"\n",
    "    log(f\"Loading data from {filepath} using pandas...\")\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(filepath):\n",
    "        log(f\"Error: File {filepath} does not exist\")\n",
    "        return [], []\n",
    "    \n",
    "    try:\n",
    "        # Try to read the file with pandas - it can automatically detect delimiter in many cases\n",
    "        log(\"Attempting to read CSV with pandas...\")\n",
    "        \n",
    "        # First try with default settings\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, encoding='utf-8', on_bad_lines='skip')\n",
    "            log(f\"Successfully read CSV with {len(df)} rows and {len(df.columns)} columns\")\n",
    "        except Exception as e:\n",
    "            log(f\"Standard read failed: {e}, trying with auto-delimiter detection...\")\n",
    "            \n",
    "            # If that fails, try with specific delimiters\n",
    "            for sep in [',', '\\t', '|', ';']:\n",
    "                try:\n",
    "                    df = pd.read_csv(filepath, sep=sep, encoding='utf-8', on_bad_lines='skip')\n",
    "                    if len(df.columns) >= 2:\n",
    "                        log(f\"Successfully read CSV with delimiter '{sep}', found {len(df)} rows and {len(df.columns)} columns\")\n",
    "                        break\n",
    "                except Exception:\n",
    "                    continue\n",
    "            else:\n",
    "                # If all attempts fail, try with the C engine which might be more forgiving\n",
    "                log(\"Trying with the C engine and Python's csv module fallback...\")\n",
    "                df = pd.read_csv(filepath, engine='python', encoding='utf-8', on_bad_lines='skip')\n",
    "                log(f\"Read CSV using Python engine with {len(df)} rows and {len(df.columns)} columns\")\n",
    "        \n",
    "        # Check if we have at least 2 columns\n",
    "        if len(df.columns) < 2:\n",
    "            log(f\"Error: CSV file has fewer than 2 columns: {df.columns}\")\n",
    "            return [], []\n",
    "        \n",
    "        # Get the first two columns regardless of their names\n",
    "        question_col = df.columns[0]\n",
    "        answer_col = df.columns[1]\n",
    "        \n",
    "        log(f\"Using columns: Question='{question_col}', Answer='{answer_col}'\")\n",
    "        \n",
    "        # Extract questions and answers\n",
    "        questions = []\n",
    "        answers = []\n",
    "        \n",
    "        # Limit to max_samples if specified\n",
    "        if max_samples:\n",
    "            df = df.head(max_samples)\n",
    "        \n",
    "        # Process each row\n",
    "        for index, row in df.iterrows():\n",
    "            question = str(row[question_col]).strip()\n",
    "            answer = str(row[answer_col]).strip()\n",
    "            \n",
    "            # Skip empty entries\n",
    "            if not question or not answer or question == 'nan' or answer == 'nan':\n",
    "                continue\n",
    "                \n",
    "            # Truncate very long answers\n",
    "            answer = truncate_text(answer)\n",
    "            \n",
    "            questions.append(question)\n",
    "            answers.append(answer)\n",
    "            \n",
    "            # Log progress for large datasets\n",
    "            if (index + 1) % 1000 == 0:\n",
    "                log(f\"Processed {index + 1} rows...\")\n",
    "        \n",
    "        log(f\"Successfully loaded {len(questions)} Q&A pairs\")\n",
    "        return questions, answers\n",
    "        \n",
    "    except Exception as e:\n",
    "        log(f\"Error loading data with pandas: {e}\")\n",
    "        log(\"Falling back to manual file inspection\")\n",
    "        \n",
    "        # Print file info as a last resort\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                sample = f.read(1000)\n",
    "                log(f\"File sample: {sample}\")\n",
    "        except Exception as e:\n",
    "            log(f\"Couldn't read file sample: {e}\")\n",
    "        \n",
    "        return [], []\n",
    "\n",
    "def train_retrieval_model(questions, answers):\n",
    "    \"\"\"Create and train a retrieval-based model using TF-IDF\"\"\"\n",
    "    log(\"Processing questions for TF-IDF vectorization...\")\n",
    "    \n",
    "    # Clean questions for better matching\n",
    "    cleaned_questions = [clean_text(q) for q in questions]\n",
    "    \n",
    "    # Create TF-IDF vectorizer\n",
    "    log(\"Creating TF-IDF vectorizer...\")\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words='english',\n",
    "        max_features=10000,  # Limit features to improve performance\n",
    "        min_df=2  # Ignore terms that appear in less than 2 documents\n",
    "    )\n",
    "    \n",
    "    # Fit and transform questions to TF-IDF vectors\n",
    "    log(\"Fitting vectorizer to questions...\")\n",
    "    question_vectors = vectorizer.fit_transform(cleaned_questions)\n",
    "    log(f\"Created {question_vectors.shape[1]} features for {question_vectors.shape[0]} questions\")\n",
    "    \n",
    "    # Create model dictionary\n",
    "    model = {\n",
    "        'vectorizer': vectorizer,\n",
    "        'question_vectors': question_vectors,\n",
    "        'questions': questions,\n",
    "        'cleaned_questions': cleaned_questions,\n",
    "        'answers': answers\n",
    "    }\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV using pandas\n",
    "questions, answers = load_medquad_data(CSV_DATA_PATH, SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_retrieval_model(questions, answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Save and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filepath):\n",
    "    \"\"\"Save model to disk\"\"\"\n",
    "    log(f\"Saving model to {filepath}...\")\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    log(\"Model saved successfully\")\n",
    "\n",
    "def test_model(model, test_questions=None):\n",
    "    \"\"\"Test the model with a few predefined questions\"\"\"\n",
    "    if test_questions is None:\n",
    "        test_questions = [\n",
    "            \"What is glaucoma?\",\n",
    "            \"How can I prevent high blood pressure?\",\n",
    "            \"What are the symptoms of urinary tract infections?\",\n",
    "        ]\n",
    "    \n",
    "    log(\"\\n--- Testing Model with Sample Questions ---\")\n",
    "    for question in test_questions:\n",
    "        answer, confidence, matched_question = get_answer(question, model)\n",
    "        print(f\"\\nQ: {question}\")\n",
    "        print(f\"A: {answer[:150]}...\" if len(answer) > 150 else f\"A: {answer}\")\n",
    "        print(f\"[Confidence: {confidence:.2f}, Match: '{matched_question}']\\n\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "def get_answer(query, model, top_k=3):\n",
    "    \"\"\"Get answer for a query using the retrieval model\"\"\"\n",
    "    # Clean and process the query\n",
    "    processed_query = clean_text(query)\n",
    "    \n",
    "    # Get model components\n",
    "    vectorizer = model['vectorizer']\n",
    "    question_vectors = model['question_vectors']\n",
    "    questions = model['questions']\n",
    "    cleaned_questions = model['cleaned_questions']  \n",
    "    answers = model['answers']\n",
    "    \n",
    "    # Transform query to vector\n",
    "    query_vector = vectorizer.transform([processed_query])\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = cosine_similarity(query_vector, question_vectors)[0]\n",
    "    \n",
    "    # Get top-k most similar questions\n",
    "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "    top_similarities = similarities[top_indices]\n",
    "    \n",
    "    # If the most similar question has high similarity, return its answer directly\n",
    "    if top_similarities[0] > 0.5:  # Threshold for \"high confidence\"\n",
    "        return answers[top_indices[0]], top_similarities[0], questions[top_indices[0]]\n",
    "    \n",
    "    # Otherwise, check if we have any reasonable matches\n",
    "    if top_similarities[0] > 0.2:  # Threshold for \"some confidence\"\n",
    "        return answers[top_indices[0]], top_similarities[0], questions[top_indices[0]]\n",
    "    \n",
    "    # Fall back to a generic answer with the most similar question\n",
    "    return \"I don't have enough information to answer that question confidently.\", top_similarities[0], questions[top_indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "save_model(model, MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with a few sample questions\n",
    "test_model(model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
